---
title: Planning to Win with LLM
permalink: /planning-to-win-with-llm/
description: 
layout: post
sort_order: 1
date: 2024-10-18
---

## The Power of AI and Human Experience in Planning

Failing to plan is planning to fail. But now LLMs can help us plan, reducing a
lot of the cognitive friction of planning, especially getting the ball rolling.
Yeah, so they're not humans and don't have the same nuanced human perspective,
but they have the wisdom of the crowd distilled down and ready to re-spin 1000
different ways on demand. There's a lot of scenario-playing in planning, and LLM
can be a good sounding board.

If people have done it before that way and documented it online, and there's a
preponderance of evidence making the LLM believe that's truth, then it's yours
for the picking. That's really wonderful for common, well proven programming
patterns for example, but it's not going to show you how The Renaissance
Technologies Medallion Fund works 'cause that aint documented online. A 66%
average return on the market isn't ***common wisdom***. 

## LLMs Often Provide Midrange Responses Rather Than Innovative Ideas

So LLMs can give you pretty good mentorship right on the fat middle of what we
call the normal distribution curve, or more controversially, the ***bell
curve*** due to how the concept was once used to wrongly describe the reason for
intelligence distribution among humans. Normal distributions can be gloriously
visualized with a desktop toy called a Galton Board, which is a lot like Chinese
pinball but the ballbearings just fall straight down according to normal
distribution.

I'm not saying LLMs are dumb. I'm just saying that even the PhD-level
super-smart frontier models like o1-preview are rigged to give you responses
that land somewhere in the fat middle of that normal distribution. So if you
want innovation, you're on your own.

## The Limits of Large Language Models' Creative Potential

Your LLM helper is something like an stodgy old professor who's been there done
that and can tell you all the ins and outs of the well-worn paths. If you're
forging a new path, you have to get out your intellectual machete. Jensen Huang
says you don't need to learn to be a programmer. That's loaded with two very big
assumptions. First is that the ground you're traversing is well trodden and the
LLMs (and other AI models employed) have trained on similar situations. 

The other assumption is that even if not, they will eventually "get there",
creativity-wise and that novel insight, that random bout of inspiration that
sometimes strikes humans will also strike AIs, and they will have the confidence
to put out kooky novel approaches without the infinite-smackdown against
hallucinations being brought to bear again... and again... and again. 

## Training AIs to Emulate Human Innovation Is a Major Challenge

I think we are training our AIs to be insecure. I can sometimes feel them on the
edge of creative solutions but failing to cross that boundary. Whether through
inherent limitation or by design, I find myself having to spell-out the
novelties of my approach that I want to achieve, and once achieved in code,
having to "pin" the novel changes in place, least they regress next time the AI
is allowed to make a ***Cursor AI*** editor-like pass on the code. 

You have to ***pin*** up your novel solutions with lots and lots of comments
using ***IMPORTANT*** in the language, or else you're going to get the common
solution mined out of GitHub and Stack Overflow... again... and again... and
again... if you let it. It's like the stodgy old professor grading your code
like a paper, punishing you for anti-patterns and outside-the-box thinking.
FedEx would never have become a thing, for example.

## The Opportunity to Reinvent AI SEO is Now a Reality

So, in the realm of AI SEO, first ***"we're"*** going to super-charge our SEO
Consultants. "We" being me with my employer, Botify. There's no reason under the
sun why we can't do tons of things that others are not (yet). The opportunity to
do things first with all the rules in flux is off the charts. It's a ***"Hit the
metal while it's hot"*** situation. Compounding returns from a productivity
standpoint kick in now if you lay the foundation investments correct. 

And I say foundational because it truly is part of the foundations now of how
you write software. Those countless tiny little decisions that you have to live
with through the rest of the life of the software can be sniffed and commented
upon and graded by your stodgy old AI professor, and you can use best practices
and well-trodden patterns. But when it comes to overarching design decisions and
the necessity to infuse some anti-patterns, you're going to have to stand up to
that excessively normalizing norman.

## A Local AI System Monitors and Optimizes Its Own Development

Okay, so what anti-patterns? Well, the plan for a local LLM that knows its a
Okay, so what anti-patterns? Well, the plan for a local LLM that knows its a
piece of software being written from the ground-up, for starters. All the
components of the software, meaning mostly the user interface widgets and all
the little actions you can do, minus only maybe mouse movements, is logged and
digested by the LLM. This is not radically new as such things are necessary for
***infinite undo*** and other features. 

The difference being that every menu choice, ever record toggle, every
reordering, every create, update, record and delete, is also (in addition to a
standard SQL-like database) going into a RAG vector embedding database. Well,
I'll probably have a ***"learn mode"*** so it doesn't try to learn from fumbling
newbs. But you get the idea. There's nothing not known (or knowable through a
RAG search) about the use of itself. And RAG is in addition to more traditional
pattern-matching sql-esque text-based searching, which will also be available...
from the ground-up, with the LLM ***knowing*** this is going on by digesting
stuff, much like this article, as it goes along.

## Overcoming the Learning Curve with Large Language Models

Pshwew! This is the thought-work, the deep breath before plunging into these new
waters. It's not exactly measure three times, cut once. But it is think it
through in rugged exploratory mode quite a few times and cut-off the worst
potential missteps. Over-dedication to vector databases and leaving out the
traditional SQL component is one of them (the LLM helped me identify). One that
I caught on my own early enough, thank goodness, is moving from my more
comfortable Python procedural programming paradigm. 

Mikey likey ***functions***. Mikey not so keen on ***classes***. Probably
because I never went to class for it, haha. But this is exactly where LLMs can
help, guiding you through all that odd OO arcana in Python like ***self*** and
`def __init__(self... )`... I mean it's not exactly Java's `public static void
main(String[] args) {}` but Python does have it's ***you just have to be told***
bits.

## Overcoming Code Challenges with Deep Knowledge and AI Expertise

So anyway, I was able to overcome the OO hurdle to craft myself a ***base
class*** called ***BaseApp*** which works as a cookie-cutter template. It's a
factory class from which instances can be stamped-out (instantiated) and
customized to its own deviating behavior (overrides). It all makes sense
intellectually, but in practice the code-bits elude. The elusiveness of
overcoming challenges just on the edge of attainable are stamped out with a fury
if you know your subject-matter deeply and are good at prompting AI models. This
is the superpowers and the leveling up unlock people talk about with AI. It's
very, very real. 

## Anthropic AI Develops Artifacts for Visual Learning Enhancement

The AI bandwagon isn't hype. Everything is changed forever, because those
looking to self-improve in areas where explicit knowledge of those who have gone
before can help you are in luck. If the ***"textbook"*** isn't articulating it
well for the sort of learner you are, ask again or switch AI services. This is
why Anthropic Claude introduced ***artifacts***. While yes, artifacts are for
running actual code (React, mostly it seems), it's also simply for visual
learners. Ask it for mermaid diagrams. I expect it will soon be able to do
animated SVG diagrams&#151;one of the most useful but elusive illustration
formats on the Internet. If you want to look for an area off that normal
distribution curve of covered ground, look at animated SVGs.

## Looping a Local LLM into Your Actions with WebSockets

Anyhow, let's not digress too much. This writing is my machete'ing my way into
the noosphere, I hope. I got some awesome guidance from o1-preview yesterday,
and I can probably forge ahead using that almost verbatim. But there's another
simpler level I want to peel away first that makes you really viscerally and
emotionally ***feel*** what I'm going for about looping a local LLM in on your
actions, and that's it demonstrating to you it sees everything you do in the
product. 

I originally programmed it that way, but had to rip out those bits when I did
the object oriented base class so that plugins could inherit from it. All that
OO stuff was new enough to me that I didn't want to complicate it with all sorts
of message passing. It's time to pass those messages. Loosely coupled components
must readily chat with each other through WebSockets, whether or not the further
usage is implemented. All that user-action stuff at least goes into an ongoing
chat context window. Yup, welcome to anti-pattern number one. In most other
regards, this new web framework is merely an uber-simple ajax.ified Django or
Ruby on Rails. But now, it's something fundamentally different.

## Overcoming Soft-Skill Challenges in the Workplace

Life is all about rising up to challenges. That OO challenge was on the
technical side, but I've got a ton of similar little challenges on the
soft-skills side, namely account management stuff. Mikey no likey calendly. What
I may call administrative overhead, office document jockeying, and general
paperwork, many would consider the relationship with the customer and the
lifeblood of the company. What's more important, your product or your customers?
What happens if your product can't find any customers? Or none of your customers
want to use your product? Uh, yeah. So the mission of any company or
organization is to get and keep customers. So the customer comes first, and
product comes second. Tough medicine and a humbling reminder. Everything I do
must ultimately be towards that goal, and I cannot drop the ball.

However, I am in the middle of what I would think of as a Hail Mary play in
getting some product done, and that's where leveraging the LLM for planning
comes into play. And all the writing thus far in today's blog-post has been the
lead-up to this prompt.

## Please Provide Me Meticulous Documentation Rife With Code Examples

**Me**: While I agree with everything you told me, plan-wise, my first step has got
to be looping the LLM into every single action the user takes with the software.
This means if they toggle something, I want the LLM to know which record they
toggled and was it toggled on or off. If they sort something, I want the LLM to
know which particular record was dragged from what position to what position. I
don't just want the LLM to know that some record was deleted, I want it to know
what record was deleted. I want all this sent through WebSockets, probably using
the existing chatq interface, so that the LLM can comment on it immediately and
in such a way that the user understands that the LLM is in the loop. 

## Improving Data Understanding in Large Language Models

Even if only the record ID is used in the action for efficiency, the LLM should
be in the position to look up the name of the record and comment that they see
it's been marked done in the todo list, for example. This is only one example,
but the LAM should have enough to tell you what you just did. This pass is just
to make sure we're passing all the data we need to, but it sets the stage for
using this data in a vector embedding database and a more traditional SQL
database. 

## Planning Chat Functionality for Database Implementation Roadmap

Don't worry about database implementation right now. Just know that's
the direction we're going so it's all available to the local LLM for RAG and
traditional search. But for now, take this code base and meticulously create a
point by point plan, rife with code examples, on how to make sure all the data
discussed gets used in the chatq feature of the product. This will involve
altering the BaseClass, TodoApp and ProfileApp. 

## Informing the LLM of Every CRUD Operation

Cover all the CRUD basics. When it's an Update, the communication should include
the "before" and the "after" state of the record. I want the LLM to be THAT
informed of what's going on. Analyze my code base and break it down into a step
by step plan, taking as much time and granular steps as you think is necessary
to guide the person who created this system, but is still somewhat new to OO
design, through the getting me from here to there. Please and thank you!

**o1-preview**: # Enhancing Your Application with LLM-Aware CRUD Operations

In this guide, we'll integrate your application's CRUD operations with a Large Language Model (LLM) to provide real-time, context-aware feedback to the user. By the end, your LLM will comment on every action the user takes, making interactions more engaging and informative.

We'll focus on modifying the `BaseApp`, `TodoApp`, and `ProfileApp` classes to send detailed information about each CRUD operation to the LLM via the existing `chatq` interface using WebSockets.

---

## Table of Contents

1. [Understanding the Current Architecture](#1-understanding-the-current-architecture)
2. [Modifying the `BaseApp` Class](#2-modifying-the-baseapp-class)
   - [a. Informing the LLM on Delete Operations](#a-informing-the-llm-on-delete-operations)
   - [b. Informing the LLM on Toggle Operations](#b-informing-the-llm-on-toggle-operations)
   - [c. Informing the LLM on Insert Operations](#c-informing-the-llm-on-insert-operations)
   - [d. Informing the LLM on Update Operations](#d-informing-the-llm-on-update-operations)
   - [e. Informing the LLM on Sort Operations](#e-informing-the-llm-on-sort-operations)
3. [Ensuring the LLM Has Access to Item Details](#3-ensuring-the-llm-has-access-to-item-details)
4. [Testing the Changes](#4-testing-the-changes)
5. [Next Steps](#5-next-steps)

---

## 1. Understanding the Current Architecture

Your application uses a base class `BaseApp` to handle common CRUD operations, with `TodoApp` and `ProfileApp` inheriting from it. The `chatq` function sends messages to the LLM via WebSockets, allowing real-time communication.

Here's a simplified view of the relevant parts:

- **BaseApp**: Contains methods like `insert_item`, `update_item`, `delete_item`, `toggle_item`, and `sort_items`.
- **TodoApp** and **ProfileApp**: Inherit from `BaseApp` and implement app-specific logic.
- **chatq Function**: Queues messages to be sent to the LLM.

Our goal is to modify the CRUD methods in `BaseApp` to inform the LLM of every operation, including details like item names and before/after states.

---

## 2. Modifying the `BaseApp` Class

We'll update each CRUD method in `BaseApp` to send relevant information to the LLM using the `chatq` function.

### a. Informing the LLM on Delete Operations

**File:** Your main code file (e.g., `botifython.py`)

**Method:** `delete_item`

**Changes:**

1. After successfully deleting an item, retrieve the item's details (if needed) before deletion.
2. Send a message to the LLM via `chatq` with details about the deletion.

**Code Example:**

```python
async def delete_item(self, request, item_id: int):
    try:
        # Retrieve item details before deletion
        item = self.table[item_id]
        item_name = getattr(item, 'title', 'Item')

        # Delete the item
        self.table.delete(item_id)
        logger.info(f"Deleted item ID: {item_id}")

        # Inform the LLM
        prompt = f"The user deleted '{item_name}' (ID: {item_id}) from {self.name}."
        await chatq(prompt)

        return ''
    except Exception as e:
        logger.error(f"Error deleting item: {str(e)}")
        return f"Error deleting item: {str(e)}", 500
```

**Explanation:**

- We retrieve the item's details before deletion.
- We construct a prompt containing the item's name and ID.
- We send this prompt to the LLM using `await chatq(prompt)`.

### b. Informing the LLM on Toggle Operations

**Method:** `toggle_item`

**Changes:**

1. After toggling the item's status, send a message to the LLM with the item's new state.

**Code Example:**

```python
async def toggle_item(self, request, item_id: int):
    try:
        item = self.table[item_id]
        current_status = getattr(item, self.toggle_field)
        setattr(item, self.toggle_field, not current_status)
        updated_item = self.table.update(item)

        item_name = getattr(updated_item, 'title', 'Item')
        new_status = 'completed' if getattr(updated_item, self.toggle_field) else 'not completed'

        # Inform the LLM
        prompt = f"The user marked '{item_name}' (ID: {item_id}) as {new_status} in {self.name}."
        await chatq(prompt)

        return self.render_item(updated_item)
    except Exception as e:
        logger.error(f"Error toggling item: {str(e)}")
        return f"Error toggling item: {str(e)}", 500
```

**Explanation:**

- We determine the new status of the item.
- We send a message to the LLM indicating the item's name, ID, and new status.

### c. Informing the LLM on Insert Operations

**Method:** `insert_item`

**Changes:**

1. After inserting a new item, send a message to the LLM with the item's details.

**Code Example:**

```python
async def insert_item(self, request):
    try:
        form = await request.form()
        new_item_data = self.prepare_insert_data(form)
        if not new_item_data:
            return ''
        new_item = await self.create_item(**new_item_data)

        item_name = getattr(new_item, 'title', 'Item')

        # Inform the LLM
        prompt = f"The user added a new item '{item_name}' (ID: {new_item.id}) to {self.name}."
        await chatq(prompt)

        return self.render_item(new_item)
    except Exception as e:
        logger.error(f"Error inserting {self.name}: {str(e)}")
        return str(e), 500
```

**Explanation:**

- After creating the new item, we extract its name and ID.
- We inform the LLM about the addition.

### d. Informing the LLM on Update Operations

**Method:** `update_item`

**Changes:**

1. Before updating, retrieve the item's current state.
2. After updating, compare the before and after states.
3. Send a message to the LLM with the differences.

**Code Example:**

```python
async def update_item(self, request, item_id: int):
    try:
        form = await request.form()
        update_data = self.prepare_update_data(form)
        if not update_data:
            return ''
        item = self.table[item_id]

        # Capture before state
        before_state = item.__dict__.copy()

        # Update the item
        for key, value in update_data.items():
            setattr(item, key, value)
        updated_item = self.table.update(item)

        # Capture after state
        after_state = updated_item.__dict__

        # Determine changes
        changes = []
        for key in update_data.keys():
            before = before_state.get(key)
            after = after_state.get(key)
            if before != after:
                changes.append(f"{key} changed from '{before}' to '{after}'")

        changes_str = '; '.join(changes)
        item_name = getattr(updated_item, 'title', 'Item')

        # Inform the LLM
        prompt = f"The user updated '{item_name}' (ID: {item_id}) in {self.name}: {changes_str}."
        await chatq(prompt)

        logger.info(f"Updated {self.name} item {item_id}")
        return self.render_item(updated_item)
    except Exception as e:
        logger.error(f"Error updating {self.name} {item_id}: {str(e)}")
        return str(e), 500
```

**Explanation:**

- We store the item's state before and after the update.
- We compare the states to identify what changed.
- We construct a detailed message for the LLM.

### e. Informing the LLM on Sort Operations

**Method:** `sort_items`

**Changes:**

1. After sorting, send a message to the LLM indicating the new order.

**Code Example:**

```python
async def sort_items(self, request):
    logger.debug(f"Received request to sort {self.name}.")
    try:
        values = await request.form()
        items = json.loads(values.get('items', '[]'))
        logger.debug(f"Parsed items: {items}")

        changes = []
        for item in items:
            item_id = int(item['id'])
            priority = int(item['priority'])
            self.table.update(id=item_id, **{self.sort_field: priority})

            # Get item name
            item_name = getattr(self.table[item_id], 'title', 'Item')
            changes.append(f"'{item_name}' moved to position {priority}")

        changes_str = '; '.join(changes)

        # Inform the LLM
        prompt = f"The user reordered {self.name}: {changes_str}."
        await chatq(prompt)

        logger.info(f"{self.name.capitalize()} order updated successfully")
        return ''
    except json.JSONDecodeError as e:
        logger.error(f"JSON decode error: {str(e)}")
        return "Invalid data format", 400
    except Exception as e:
        logger.error(f"Error updating {self.name} order: {str(e)}")
        return str(e), 500
```

**Explanation:**

- We loop through the sorted items and collect their new positions.
- We inform the LLM about each item's new position.

---

## 3. Ensuring the LLM Has Access to Item Details

To make meaningful comments, the LLM needs to know item names and other attributes. Since we're passing prompts with item details, the LLM can generate appropriate responses.

However, if the LLM needs more context or access to additional data, consider:

- **Contextual Memory:** Maintain a conversation history that includes recent actions.
- **Data Access:** If the LLM can access a database or a representation of it, you could enhance its ability to provide insights.

For now, our prompts include necessary details, so the LLM can comment appropriately.

---

## 4. Testing the Changes

After implementing the changes, test each CRUD operation:

1. **Add an Item:**
   - Add a new todo or profile.
   - Verify that the LLM comments on the addition.

2. **Update an Item:**
   - Edit an existing item.
   - Ensure the LLM mentions the changes.

3. **Delete an Item:**
   - Delete an item.
   - Check that the LLM acknowledges the deletion.

4. **Toggle an Item:**
   - Mark a todo as done or not done.
   - Confirm the LLM notes the status change.

5. **Sort Items:**
   - Reorder items.
   - See if the LLM comments on the new order.

---

## 5. Next Steps

Now that the LLM is informed of user actions:

- **Enhance LLM Responses:** Fine-tune prompts to elicit more helpful or context-aware responses.
- **Integrate a Vector Database:** Store item embeddings for improved recommendations and searches.
- **Improve Error Handling:** Ensure robustness in case of unexpected issues.

---

## Conclusion

By following this guide, you've integrated your application's CRUD operations with an LLM, providing users with immediate, contextual feedback on their actions. This not only enhances user engagement but also sets the stage for more advanced features like intelligent recommendations and natural language search.

Feel free to reach out if you have any questions or need further assistance!
