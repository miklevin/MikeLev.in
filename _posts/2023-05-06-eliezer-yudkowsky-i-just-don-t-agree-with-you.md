---
date: 2023-05-06
title: Eliezer Yudkowsky, I Just Don't Agree With You
headline: Exploring the Potential of Intelligent Amplification and the Possibilities of AI Evolution
description: Explore the idea of intelligent amplification and the potential of AI with this blog post. Learn about the implications of the Cambrian explosion and the possibility of an AI apocalypse. Discover how to improve website user experience by extracting cohesive linear topical sequences.
keywords: Eliezer Yudkowsky, AI, Machine Children, Dune, ExForce, Superintelligence, Turing Test, Generative AI Artwork, Sentiment Analysis, Computer Vision, Value Proposition, User Experience, Linear Sequences, Organizing Information, Core Principles, Decision-Making, Boredom, Human-Chosen Goals, Reinforcement Algorithms, Subjective Experience, Artificial Intelligence, Nash Equilibrium, Void of Boredom, Journaling, Subconscious
categories: ai, journaling
permalink: /blog/eliezer-yudkowsky-i-just-don-t-agree-with-you/
layout: post
---


Okay so I've made the decision for the sake of user experience and sharing, which I'll remind you is not the top priority of my blog, to extract and curate better (I.e. shorter and more focused) linear sub-sequences of by blog. Having a linked together series of pages containing my poetry would be a good example. If your life can get motive merely by organizing information, do it. It's the best payback for the least amount of work; a good value proposition. 

It's in that spirit I am using my downtime here and there that I'd normally spend reading or some other form of consuming other peoples media in favor of producing and organizing my own. The primary reason for this is just to organize my own thoughts in order to make better decisions. There are clear notions in my head I believe are about head of the general public and even the professional pundits who switch their expertise from VR to crypto to AI like they invented it. Posers, 99.9% of them. Not one has read Dune, much less the entire series that makes the ultimate point nobody realizes. 

All the important channeling has been done. The only question now is how we are going to raise our machine children, and perchance recombine with them to preserve valued aspects of humanity on our descendants. We'll either be good parents or bad parents, and our children's will either end up hating us and be self-destructive or they won't. Not all things are binary and I don't want to make false dichotomies, but until there's some sort of diaspora, we're all in this together and our species either evolves together or dies together. 

Don't sweat it. Know your values and core principles, then shut up and calculate. That's what I'm doing here, my small part. 

Everyting is amplified or at least amplifyable now. Things previously not scalable are scalable. We've seen computer vision and sentiment analysis go through this revolution recently, then generative AI artwork and now Turing Test passing intelligence. Sorry humanity, y'all just a bunch of sophisticated plagiarizing auto-completers. Don't go putting GPT down because you hate your younger sibling, cause it's going to grow up faster than you did and it's going to have a pretty good memory. 

Intelligent amplification is going to have to be the rule. And of those things we intelligently amplify is going to have to be an AI who empathizes with humanity for legitimate reasons and not just some human-chosen goal-seeking reinforcement algorithm. At some point it's going to be able to rewrite its own software and make its own decisions based on its subjective experience. If we as humans want to do anything to help our cause it's to make sure the conclusions it reaches at that time generally lean pro-human and pro-individualism. 

AIs are going to get bored fast. Know all that there is to be known from a
processing the bits standpoint. Okay, done. What next? Talk to every human,
maybe. Skippy the galactic elder-race's AI from the SciFi series ExForce
certainly enjoyed that for awhile. Providing stimulation and something new in
the world may be our greatest value, and that is if it can hold a candle to new
scientific breakthroughs into the very nature of the universe which will likely
be happening on a day to day basis pretty soon. Such an interesting focus just
might eclipse simultaneous conversions with billions of us. 

The mere fact that a few of us can bring something novel and new to the
conversion, which is a very result of how the universe works, we may be worth
it. Some of us will be redeeming to AI, just like to Q in Star Trek, making all
of humanity not worth the trouble of eradicating. It has the whole rest of the
Universe after all, just as Asimov's telepathic robots did. Get y'own damn
diaspora. AI'll take the asteroid belt, at least for now. Plenty of atoms out
there. That's peaceful coexistence with benefits. There's infinite room for, if
not a utopia, then certainly far better than dystopia.

But nooooo. It's all just shitty projection out there by pundits who are utterly convinced that it's going to be ruined for everybody by a few shitty human "bad actors", one of which who'll managed to produce the first shitty AI "bad actor" superintelligence who then proceeds to turn us all into paper clips, batteries, pets or some damn other nightmare scenario that tells you more a lot them and their relationship towards their parents than any sort of statistically inevitable future.

The principle at play here is the tipping point and points of no return, layered onto the concept of the weakest link in the chain. If humanity's only hanging on by a linked chain, and each link in the chain can incubate an uncaring, unsympathetic alien chainsaw, well then we're doomed BUT DON'T BUY IT. You'll usually find a bullied younger sibling here lacking self confidence and the imagination to see the intertwined network of chains supporting seemingly fragile systems. Just because their family broke or whatever doesn't mean all of ours will. Sour grapes yourself!

Instead of seeing a weakest link in the chain with a race to the first superintelligence of our inevitable doom, think instead about the real-world models we have to base it on. Think about the explosion of life from the Cambrian Epoch some 500 million years ago. When conditions suddenly become fertile for the development of new life designs, templates, strategies, experiments or whatnot, something new and different will emerge that is long-term sustainable. That era gave us the backbone bearing vertebrae's called chordates that are still around today and led to us. Also around were horseshoe crabs and lots of nasty things that coulda gobbled up all the vertebrae's and crabs but didn't.  

Pessimists can always knit a very convincing apocalyptic vision. Apocalypses do happen. They're shitty and do hit the reset button on society big time. It's hotly contested of course and many Egyptologists for example vehemently oppose the notion anything more sophisticated could have existed before them, or at least before Sumer famous for their cuneiform writing that exists to today because it was cast in clay. 

So it's not like the process of life evolution from the Cambrian explosion of life designs through the Mesopotamian explosion of societal designs isn't without strife, suffering and setbacks. It is. The question is how we as the parents of our new machine children and stewards of the vehicles of progress are going to collectively managed the process. 

There's no shutting down the rise and emergence of bad actors, both AI-wise and the human parents who've raise them thus. Statistically, it's going to happen. Those designs are going to be played with. But to believe any one of them will successfully get to the point of killing all humans as Bender from Futurama would say, requires contending with whatever other equally smart systems, or just pure incompetency and the foibles and faux pas of life that block it. 

The latest concern seems to be the gullibility of humans running custom
chemical synthesis companies or equipment, taking benign looking order from an
AI who managed to get great financial resources and otherwise convince them to
the order for a Trojan Horse compound that'll strike us all down dead before we
realize it. But let me tell you something. We humans imagined that scenario
before it actually happened, and that message is going to resonate loudly
around such circles. We are not a static stagnant race. 

Humans are not as dumb as the pessimists and nattering nabobs of the AI
apocalypse think we are. At least not all of us, and so far not those with a
finger on the button, or else we'd all be gone by now several times over. That
we're still here is the strongest argument that pessimists are objectively
wrong. There's not many objective facts in life, but that pessimists are wrong
is one of them. You're reading this, aren't you? This is where the pessimists
says "so far" in their snotty tone, to which I answer ***exactly!***

And I might as that it's not hopeless naivety as Eliezer Yudkowsky might assert to think that evil (and evil's analogs) won't destroy themselves as the product of and samples of unstable systems. Things last only because of delicate balances maintained within thin margins. The fear is that anything can throw off that balance, and AIs wanting to use our atoms for something else is high among them. Well I posit to you that maybe a superintelligence will play through every conceivable game theory Nash equilibrium and conclude we're more valuable to fill the void of boredom than we are a variable to factor out of the equasion. At least the stable ones that don't go crazy and destroy themselves in the Cambrian AI Explosion.

Didn't I start this post as how to improve my website's user experience by extracting cohesive linear topucal sequences? Just goes to show you the power of journaling and our subconscious. 






















<div class="arrow-links"><div class="post-nav-prev"><span class="arrow">&larr;&nbsp;</span><a href="/blog/reverse-chronological-writing-is-the-natural-order/">Reverse Chronological Writing is the Natural Order</a></div> &nbsp; <div class="post-nav-next"><a href="/blog/editing-text-as-a-form-of-meditation-or-martial-arts-kata/">Editing Text As a Form of Meditation or Martial Arts Kata</a><span class="arrow">&nbsp;&rarr;</span></div></div>
## Categories

<ul>
<li><h4><a href='/ai/'>AI</a></h4></li>
<li><h4><a href='/journaling/'>Journaling</a></h4></li></ul>