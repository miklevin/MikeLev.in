---
title: "API, AI & Human Nuance: The Same Thing"
permalink: /api-ai-human-nuance/
description: 
layout: post
sort_order: 1
---

## How to Not Be Blindsided By Nuance

The intensity of my work is only increasing as I near the finish-line of the
steep startup cost of a project. Any large endeavor front-loads expensive
startup costs, because you need to try things and learn the ropes. It's not like
you come out of the starting gate knowing all the nuance of subtlety of some new
thing, no matter how experienced you are. Today's article is about running into
all those new learnings with AIs, APIs and similarity to humans (in both
regards).

### Shoshin and Questioning First Principles

Sure, experience helps when you're tackling new stuff but if everything was
really that similar, there would be no challenges. The skill lies in sorting the
weird newness that takes special attention from things where your old chestnuts
make you immediately adept. Shoshin&151;be like a beginner or you're going to be
working off of bad initial assumptions, axioms, first principles or whatever
buzzword you wanna call your understandings at the outset.

## Frontier LLM AI Models Take Step Forward with 'o1-preview'

I bring this up because each LLM AI model you work with has its own nuances and
subtlety. They have slightly different sets of base assumptions you can make.
This wasn't so dramatic except maybe the move from ChatGPT 2 to 3 where you
really felt like you were talking to something significant. ChatGPT 4o as much
as it's assumed as the standard today doesn't give you much of a different vibe
than 3. But the new o1-preview model takes another one of those leaps, and it's
easy to feel it's super-intelligent. I can see what the big hullabaloo about the
***strawberry*** codename was. What did Ilya see, and all that. Well, I've been
using it awhile now, and as brilliant as the version of it that reached the
public is, it can still lull you into a false sense of security of its ability
then blindside you with its own blindness. Ouch! 

### Approaching AI Like a New Employee at a Job

That was yesterday. It's not going to be able to look at 2 codebases loaded with
its own subtlety tied to how browsers render things and how the http
communication goes on in the background and statefulness is maintained and be
able to switch you over from one way of doing things to another. At least not
without a lot of pain from being isolated from factors that you shouldn't be
isolating yourself from. You should let yourself get up-close and personal with
the porting issues so when it fumbles, you know precisely where. Or better
still, so that the way you prompt it to help you never actually opens the
opportunity for the fumble. In other words, you can approach interaction with AI
the same way you would with a clueless fresh out of high school employee on
their first job, or in the way Joel Spolsky talked about it in his... uh...
uh...

---

**Me**: What is the Joel Spolsky seminal article on not letting bugs get into your software in the first place? The whole proactive limiting the opportunity for them to arise thing?

**Perplexity**: The article you are referring to is likely "Hard-assed Bug Fixin'" by Joel Spolsky, published on his blog, Joel on Software, on July 31, 2001[2]. In this article, Spolsky discusses strategies for identifying and fixing bugs that are economically worth addressing. He emphasizes the importance of fixing bugs only when the value of having them fixed outweighs the cost. The article also details methods such as trapping bugs on demo servers and collecting logs from crashing applications to proactively identify and address issues before they become widespread. This proactive approach aligns with the concept of preventing bugs from arising in the first place.

Citations:

    [1] https://www.qable.io/blog/prevent-bugs-in-qa-testing
    [2] https://www.joelonsoftware.com/2001/07/31/hard-assed-bug-fixin/
    [3] https://dev.to/checkgit/the-joel-test-20-years-later-1kjk
    [4] https://www.joelonsoftware.com/2000/11/08/painless-bug-tracking/
    [5] https://www.joelonsoftware.com/2001/12/25/getting-things-done-when-youre-only-a-grunt/
    [6] https://jhall.io/posts/solve-every-problem-twice/
    [7] https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/
    [8] https://www.reddit.com/r/ExperiencedDevs/comments/18vxqqf/24_years_ago_joel_spolsky_joel_on_software_wrote/

---

## Eating The Frog to Take Stress Off Yourself

The main thing this morning is to not get distracted. This tiny time window you
are allowing yourself for laying the foundations of this defending-against-bugs
port is slim. Ugh, it's not like you're going to make a hail mary play and
finish the port this morning. You have to take the stress off yourself of the
upcoming meeting, and switch into that mode.

## Even The Hound Must Rest

Hit it out of the ballpark with managing meetings today. First of all, think out
loud about the process and go ahead and blog it right here. There's no shame in
trying to be (or at least look) competent in an aspect of your job you're being
distracted from by a true passion. This coding stuff and the challenge of being
on the chase like the way Watson used to describe Holmes on the scent of a case
is exactly the trilling feeling of coding an interesting project. 

## Using Gamification Algorithms for Self-Control and Productivity Gains

It's just the right level of just-beyond-reach but around the corner you need.
The game gamification and level-seeking and unlocks has been used a lot lately
for the kind of addiction developers of ***the algorithms*** are using to get
you and keep you addicted to social media for that slot-machine pulling dopamine
rush. Doom-scrolling and dragging down at the top of a feed for a refresh.
Insidious stuff, but you can use that power for good with self life-hacks.


