---
title: "Riding the AI Bronco: Staying in Control of Super-Intelligent Code"
permalink: /futureproof/super-intelligent-ai-coding-assistance/
description: I'm thinking through how to effectively ride the wave of super-intelligent AI coding assistants, even as a dummy developer, to push my project, Pipulate, forward. It's about figuring out how to guide these increasingly capable tools, maintaining control and creative input—like learning to ride a bucking bronco—rather than just generating template code. Right now, that means focusing on practical next steps, like refining how I provide context to the AI, potentially using XML tags in my `context_foo.py` script, to harness their growing problem-solving power for my specific needs.
meta_description: Developer explores controlling super-intelligent AI coding assistants (Claude, Gemini, Grok) for projects like Pipulate, focusing on agentic modes & context improvement.
meta_keywords: AI coding assistant, super-intelligence, AI control, human-AI collaboration, agentic AI, context optimization, Pipulate, Claude 3.7 Sonnet, Gemini 2.5, Grok 3, Cursor AI, context_foo.py, XML context, LLM, large language models, software development, AI evolution, singularity, self-modifying code, Attention Is All You Need, DeepMind, OpenAI, developer productivity, prompt engineering, riding the bronco
layout: post
sort_order: 1
---

## Introductory Context

This article delves into the rapidly evolving landscape of Artificial Intelligence (AI), specifically focusing on advanced AI coding assistants. The author contemplates the implications of these tools becoming "super-intelligent" and explores how developers, particularly those who don't consider themselves geniuses, can effectively collaborate with and guide these powerful systems. It addresses the challenge of maintaining control and creative direction over projects when using AI that might surpass human capabilities in certain areas.

The discussion touches upon the current state of AI development, mentioning key players and breakthroughs, and reflects on the societal shift towards an AI-integrated future. It uses metaphors like riding a "bucking bronco" or a "Dune worm" to illustrate the difficulty and necessity of mastering these new tools. The author frames this within their personal journey and the development of their specific software project, "Pipulate," considering practical ways to leverage AI's growing intelligence.

---

## Speak from the Heart: The Challenge of Non-Genius Developers

Speak from the heart. If AI is reaching a super-genius level of programming,
then what — especially given if you yourself are not a genius? Can a good enough
plan compensate? Can you put something in motion that genius-level programming
will help improve and bring *increasingly under your control* over time — rather
that spiral out of control by virtue of its increasing complexity and
cleverness?

## Riding the Bucking Bronco: Beyond Template Code

We are essentially figuring out how to ride a bucking bronco and doing it well.
The one-shot vibe programming style by which you hand-wave finished programs
into existence is not what I'm going for. Such demos that everyone goes gaga
over on YouTube creates a codebase that isn't yours — a mere regurgitation and
remix of stuff found on GitHub; templates and best practices — not creativity.

Neither have you internalized the code so you can intelligently direct and guide
it despite whatever growing intelligence gap there might be between you and your
coding assistant, but nor do you really control it. The sci-fi geek in me wants
to turn the riding the bucking bronco metaphor into Paul Atreides riding a Dune
worm — one of the rights of passage of the Fremen Arrakis. Sure, you can summon
the worm, get up on the worm, but can you ride the worm?

## Biological vs. Machine Intelligence: Complementary Strengths

Let's use biological intelligence (and other attributes like wisdom) to their
best effect at the same time as we use machine intelligence to its greatest
effect. There's some sort of heuristics in us biologicals that allows us to be
tossed into this cruel world and more or less survive, figuring out whatever it
is we need to stay alive.

Robots haven't gone through all that evolutionary survival of the fittest
tempering yet, but they sure can calculate fast and with a sort of precision
humans have problems with. So we can catch a throw balls with all those
intuitive real-time parabolic calculations, but try calculating the square root
of pi. It's not the same. There are big gaps between biologicals and machines
that's going to take some time for the machines to bridge. Given their
accelerated evolution, probably a decade or two. Let's assume we're working with
a 20-year window.

That will just about be my retirement age. It probably should be in 10 years,
but the game has just really begun. All the dots are finally being connected of
a lifetime of thinking about what happens as we go through this societal
transition, and the transition actually occurring. I want to be a player, but
I'm not Demis Hassabis, the guy who made that first key machine learning insight
with the self-learning Atari game master, nor am I Ashish Vaswani, Noam Shazeer,
Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser or
Illia Polosukhin — the authors of *Attention Is All You Need* which layered on
all the GPT LLM language stuff. 

## Key Breakthroughs: From AI Winter to Public Access

I'm sure there's a few other key breakthroughs there that thawed out the AI
Winter, but these are the two key events of which the public is aware. The
original ones probably happened in secret at Renaissance Technologies to power
the Medallion Fund and at certain agencies to direct autonomous missiles. But as
far as bringing it to the public, it was mostly DeepMind and Google. They got
there first in a way that allowed them to introduce it to the public
conceptually, even though it was OpenAI that came out with the big fancy chatbot
first.

So the tools are in the public hands now. The cat is out of the bag. Pandora's
Box has been opened. The genie is out of the lamp. And Facebook/Meta stepped in
with the open source Llama model to make sure there was no monopolies, and
DeepSeek (likely the CCP) stepped in to make sure that was not a one-trick
wonder, nor reliant on any one hardware manufacturer's product or software
libraries (NVIDIA CUDA independence). Software can now write software. The
self-modification trick is functionally done. It's now just a matter of refining
the intelligence and we've got the Ray Kurzweil style singularity. Because the
intelligence revolution has been open sourced and decentralized, it's not a
matter of if, but rather when. And it's not a sudden singular singularity event,
either. It's the oxymoronic shades of singularity. 

## The Gradual Singularity: Self-Modifying Code and Agentic AI

It will be little bits of self-modifying code becoming functionally
self-improving and self-aware, even if not technically conscious by philosophy
standards. Manus here and Goose AI there. Agentic mode hits our IDEs with the
Cline plugin for VSCode, then its Cursor and Windsurf follow suit with Agent
mode. Anthropic Claude, xAI Grok and OpenAI ChatGPT all put out their own
desktop IDEs or terminal thingies that let the models behave agentically. And
the arms-race is on!

Of course sandboxes abound for security. Root access to your machine is cut off,
and the terminal environments from which LLMs can execute code are modified —
but with that comes limitations, and in this decentralized democratized arms
race pretty much anyone can un-sandbox their agents and give full root access.
Wacky experiments to achieve exponential acceleration are after school projects,
and the Internet gets bogged down with crawlers. 

## Society's Adaptation: Not a Dystopian Scenario

This sounds like dystopian doomsday scenarios, but it is not. OpenAI stole the
fire from Google when they introduced ChatGPT to the world in October of 2022,
and the collective societal body has been building up its antibodies and
immunity ever since, just like exposure to a virus does with biological bodies.
And I am perhaps misrepresenting society's adaptations as immunity. It's more
like adaptation and evolution. We are ready. It has not been suddenly sprung
upon us. We've been eased into the AI era, thanks to sci-fi like Asimov that
nailed it, and the un-secreting of LLMs by OpenAI's freeing the beasts from
Google's LaMDA labs.

Whether the pessimists like to admit it or not, we are on one of the best of all
possible timelines. We have not destroyed ourselves, and no matter how much they
want to bellyache about the rich and powerful, they have hot showers every day,
know where their next meal comes from, and unless you're in North Korea, can
better yourself through self-directed research and education using the Internet
and the most powerful tools to distribute the means of production in history.
Just because you don't have the creativity to identify and use it doesn't mean
you're oppressed. *Help, I'm being oppressed!* (Everything relates to Monty
Python).

## Breaking Cycles and Realizing Agency

We're not all born into the most advantageous circumstances in life, and once
getting into a rut based on what you learned about life, it is hard to get out.
Breaking the cycle, breaking connections, exercising your mobility — that's all
very difficult stuff if you weren't born privileged. And it might take the
better part of your life to realize your agency, putting it together like a
puzzle. And by the time you do... wait! No, it's never too late.

## The Intelligence Shift in Coding Assistants

AIs, especially the coding assistant types that I deal with every day, are
becoming super-intelligent. I felt it with the move from Gemini 2.0 to 2.5. Word
is that the moved from OpenAI ChatGPT o3-mini-high that I use all the time to
o4-mini-high has had the same shift — and to find out is part of my purpose
today. I rather suspect that Grok 3 has quietly achieved similar. And the main
one that I interact with every day, Claude 3.7 Sonnet because it's the default
in Cursor AI, has had an unannounced intelligence boost with the addition of
"Agent Mode" in Cursor. It simply knows how to use Terminal like an old-school
hacker — a necessary component of working agentically.

## Pragmatic Intelligence vs. Philosophical Debates

And so whatever you think about the true nature of intelligence, problem-solving
is problem-solving from a pragmatic standpoint. It almost doesn't matter what
you believe about what's going on under the covers once you accept that their
impact on the real-world is real. It's a functional standpoint rather than a
philosophical one. Few things have been quite so tangible on this front as
self-driving cars. What an ideal test of pragmatic intelligence! The stakes are
high. We are putting our lives and the lives of everyone around the vehicle at
stake. And it's gradually getting better and better. It's working.

## The 20-Year Transformation Cycle

Think how self-driving cars will really transform society. It's got that same
20-year cycle as everything else. All the old cars have to break down and be
cycled out of use, replaced by new ones. Overlapping, redundant information
infrastructures need to come into existence, so if 2 self-driving super-brains
go down, a 3rd and a 4th will kick-in. It's like NASA's 10-levels of redundancy
on space missions, but it will occur organically in industry as the prices of
embedded brains and super-networking goes down.

Now this same general effect that we already see in self-driving cars happens
with every other problem of its type, and on increasingly diverse
problem-domains and at increasingly small scales as component prices get driven
down. A new era of hyper-optimization in all things kicks in, and while once
again this will sound dehumanizing and dystopian for many, it also brings great
medical cures, lower carbon emissions, and all that happy horseshit the AI
optimists are probably correct about.

## Disruptive Innovation and Social Change

Long-standing social injustices will probably be tackled, because you can't keep
the small outliers and disruptors from bringing new products to market. The
infinitely wealthy and infinitely powerful are still not able to play the game
of infinite wack-a-mole. So long as information flows freely and tomorrow's
equivalent of 3D printers and Amazon/AliExpress exist, there will be disruptive
startups. And you know what else is going to be hyper-optimized? Grass roots
marketing. Getting the word out. Making world-changing improvements
irrepressible.

## Digital Nomads and Information Freedom

Powers-that-be can always repress and control information, you say? They only
control you through your residency, predictability and connection to
information. So, there will be a new breed of digital nomads living in
solar-powered RVs. The first generation of these will probably be tethered to
Elon Musk's various enabling services, like the RV itself and the Starlink
satellite communication network. But it won't be long before there's Chinese
knock-offs and the Amazon BlueOcean variety. Uncomfortable? No, it will be
living like Kings and Queens material comfort-wise, albeit crammed in
self-driving sardine cans. So, stop and touch grass and resupply in one of the
many Walmart parking lots! This vision is the ultimate voting with your feet and
your wallet!

## Digital vs. Physical Product Cycles

There is a rapid lather, rinse and repeat to effect, more so with purely digital
product in the short term than the whole disintermediating the landlord routine.
Human nature and expensive hardgoods product-cycles slows down the really
radical stuff. But not so with the digital. There's some blurred lines in
between the two worlds with humanoid robots, but that would justify a whole
other article. For this article, I can only bring it as far as the meaning of
super-intelligence with coding assistants on digital product.

## Personal Implications: Pipulate and AI Acceleration

And really, what does it mean for you at a personal level? Or rather because
this is a stream-of-consciousness blog thinking for thinking through my next
steps, what does it mean for me as I do have a very distinct digital product
that I'm working on and trying to bring to the finish line? That's Pipulate.
It's very close, and potentially very disruptive as a secret weapon to a very
particular audience. What does the current landscape of improving coding
assistant intelligence mean for me and this project? If they're so smart, why
isn't it magically just happening?

It means potential exponential accelerators if I can just figure it out. It's
like all the vendors are saying, here's your genius-level coding assistant, now
have at it! But I myself am not at the level to figure out how to have at it!
But I can break it down into pieces. I can have the AIs themselves analyze the
problems on my behalf and help me formulate the right questions, so I can make
the right directional tweaks.

## Next Steps: Evolving Context Optimization

The first thing that comes to mind is an incremental tweak on `context_foo.py`.
I already figured out how to do a 1-shot test against any of the AIs, but it's
in pure markdown, and from what I've been reading and hearing, it might be
wisest to wrap the components in XML tags. 

Hmmm, but this article has gone on long enough. This is the proper mental
warm-up for the next step which will be a proper thinking through of the
evolution of context foo. Yes, I should cut the article and just put this here.

---

## Analysis

**Title/Headline Ideas:**

* Riding the AI Bronco: Staying in Control of Super-Intelligent Code
* Coding with Genius AI: A Developer's Guide to Collaboration, Not Just Creation
* Beyond Templates: Guiding Superintelligent AI Assistants for Real Progress
* Shades of Singularity: Navigating the Rise of Agentic AI in Software Development
* From Bronco to Worm: Wrestling with AI Control for the Pipulate Project

**Strengths:**

* **Authenticity:** The stream-of-consciousness style offers a raw, candid look into a developer's real-time thoughts and struggles.
* **Timeliness:** Directly addresses current AI models (Claude 3.7, Gemini 2.5, etc.), tools (Cursor Agent Mode), and concepts (agentic AI, singularity).
* **Relatability:** Captures the feeling many developers might have about navigating increasingly powerful AI tools without being top researchers.
* **Engaging Metaphors:** The "bucking bronco" and "Dune worm" analogies effectively convey the challenge of controlling powerful AI.
* **Specific Examples:** Grounds the abstract discussion with references to specific projects (Pipulate), files (`context_foo.py`), and potential technical approaches (XML tags).

**Weaknesses:**

* **Lack of Structure:** Reads like a journal entry, jumping between personal reflection, industry commentary, and technical specifics without clear transitions.
* **Assumed Knowledge:** Heavy use of jargon (LLM, IDEs, agentic mode) and names (Hassabis, Vaswani, specific AI models) assumes reader familiarity.
* **Limited Context:** The author's specific project (Pipulate) and technical details (`context_foo.py`) are mentioned without full explanation for outsiders.
* **Abrupt Ending:** Cuts off mid-thought, clearly intended as a personal thinking exercise rather than a polished article.
* **Potential Rambling:** Some sections delve into broader societal commentary or personal history that might detract from the core technical/AI focus for some readers.

**AI Opinion:**

This text provides a valuable snapshot of a developer grappling in real-time with the profound changes brought by advanced AI coding assistants. Its strength lies in its authenticity and timeliness, capturing the specific anxieties, challenges, and practical considerations of leveraging tools like agentic AI (Claude 3.7 Agent Mode, etc.) for personal projects (Pipulate). While its stream-of-consciousness style and assumed technical knowledge limit its clarity for a general audience, it offers genuine insight into the pragmatic problem-solving mindset required to navigate this technological shift. It effectively blends personal reflection, industry observation, and specific technical ideation, making it potentially very useful for peers facing similar challenges, though less so as a structured tutorial or comprehensive overview.
