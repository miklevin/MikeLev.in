---
date: 2023-03-07
title: What is the best thing I can do for Moz as a subject matter expert?
permalink: /blog/what-is-the-best-thing-i-can-do-for-moz-as-a-subject-matter-expert/
headline: Become a Linux Server Admin and Junior DevOps Person in Days with LPvg and AI Automation!
description: I'm Mike Levin, an SEO in NYC passionate about learning Linux, Python, vim & git (LPvg). I'm advocating for the use of Linux API and Debian-style repo startups to help automate tasks and speak on behalf of the spoken word. I'm currently working as a Subject Matter Expert for MOZ and helping people go from Windows or Mac laptop users to Linux server admins and junior devops people and data engineers.
keywords: SEO, NYC, Linux, Python, Vim, Git, LPvg, Linux API, Debian-style repo, Windows, Mac, Subject Matter Expert, MOZ, Automation, Scripts, Apps, Networks, Data Engineering, Excel, Manual Steps, AI, JupyterLab, Apache, MIT, Licenses, Humanly Accessible API-Layer, Type-2 Automation, Python, Pandas, Proprietary Tools, WSL, Jupyter,
categories: moz, python, nyc, vim, linux, mac, excel, ai, lpvg, wsl, jupyterlab, git, seo, automation
layout: post
---

Hello World. TLDR: This is an introduction and an argument for a tech platform for SEO called LPvg, for Linux, Python, vim & git. It's based on the world being suddenly different because Ubuntu Linux just became a canonical part of Windows and Mac. Therefore, the era of generic tech is upon us, and now is a good time to jump on the bandwagon. The rest of the article is how.

I'm Mike Levin, an SEO in NYC. I'm really from the suburbs of Philadelphia, but I optimized SEO opportunities by moving to NYC. Lots of fun stories, but who cares? Fast-forward to today where I've made a good living and connected with a passion deeper than SEO that I find quite delightful and love-worthy and would like to share with the world.

It's a secret about becoming more technical, and thus more literate and more capable in today's world even in the face of AI and in a way that doesn't go obsolete on you every 2 to 5 years. That kind of stuff makes my blood boil and I've fought against excessive change in your tools over the years.

Change is good. Change is inevitable. Yet change must be minimized at core for those who learn slow, learn well, love craft and want to be doing some love-worthy thing in some increasingly adept and evermore savvy way for maybe your whole time in this world because you love it so much. Lots of people have that in many fields, and now you can too… in tech!

What the heck do I mean by this? Well, your skills and ability to do good, useful and always relevant work should hop from platform to platform over the year without much loss or setback. I've been on platforms that died which were full of love-worthy things, many tied to a particular state of computer hardware with unique capabilities like the Amiga. But much tied to text.

Tied to text? I mean the type-in user interface traditionally about 80 characters across and 25 characters high inherited from the world of over-telegraph and over-satellite remote typewriter tech that got named teletype, or TTY, this all got based on. Thus the naming convention.

Characters across by characters up and down  that define an interactive text screen may change, but this is an alternative way to interact with computers that still surprisingly pervades our world as a "lower level" way to control computers which lends itself to automation better than point-and-click graphical user interfaces because… we'll, because of details of how the human/machine interface works. You can write "scripts" in text-land.

And so this text user interface, or command-line interface (CLI) or Terminal or Shell is thus proving to be rather surprisingly portable, consistent and yet quite resilient interface over the years and over many platforms. There is value in learning it. Yes, this sounds scary and intimidating. Yes, this is everything Steve Jobs promised us was in the past with GUIs. But yes, this is where much true long-term valuable tools are found.

Linux, Python, vim and git sort of run on each other and in union with each other. Other components do this too and some such as Standard C or LISP have truer claim to being fundamental and universal. However, our criteria includes the 80/20-rule and that is trying to get 80% of the benefit of an undertaking from the first 20% of effort or resources you're overall willing to allow for if.

In other words, they're all easy enough—we'll, maybe all but vim which is worth it. They're all actually free. And they're all well integrated into many companies critical infrastructure and so will never die. They're also each well proven to resist corporate clobbering like Java got from Oracle. LPvg all have good FOSS licenses keeping them FOSS. They are the recipients of a righteous feedback loop and together constitute a rather effective yet still quite secret bandwagon.

Why? Because of how quite so shockingly different are the two worlds of graphical user interfaces (GUIs) and command-line interface (CLIs). People who have only ever lived in GUIs all their lives. We're several generations into being taught to fear the CLI. We feel it instincitively, looking at that blinking cursor and not knowing what to type. But Steve Jobs fanned the flames of those fears, we all bought it, and today few know the first keystroke about CLI. That's sad and that ought to change.

A new class of information agnostic data wizards is upon us. Why? Because \*nix in general and Debain-based Linux in particular is their starting platform and therefore server-build scripts targeted towards either Windows or Macs will give you 1 Ubuntu server's worth (unit?) of general computing power. It'll have an IP and be on the Internet, and thus connect ot many potential data-sources. It may or may not have a desktop graphical user interface. It certainly wont have to. Target a platform such as that and your abilities will always be relevant. You'll always be able to create servers (long-running scripts) or run scripts on a schedule. Sound boring? It's like Mickey in Sorcerer's Apprentice, but done well.

Who wouldn't want to automate a script to do your work for you, or at least the automate-able parts of it? Yeah, doesn't excite everyone as much as it does me. But it boggles my mind the extent to which people will go to run an andvanced Excel macro or VBA Script or AppScript or whatever else proprietary languge is built into some vendor's proprietary tool that takes entirely as much technical work and skill to use as Python on Linux does.

But these same people who will spin their wheels in Excel will never in their lives get to a point where thy can run a little Python on Linux. To me, this is a career shall-out. Wake up! The world is your oyster if only your magic hand gestures that make deliverables weren't so tied to analog hand movements and highly relative feature-maps. Hand gesture magic is more fragile than encoded words, even if ultimately expressed as hand motions too because keyboards.

So I am here speaking on behalf of the spoken word, as encoded through the use of a standard keyboard. The particular commands I endorse are those initially through the Linux API after a standard Debian-style repo startup. Actually, you control the startup too, but we'll get to that later. I'm offering here one such running instance that a script of mine will set up on your machine. It's a magic spell.

Or at least I'll pitch it that way in the social medias because if any of you know me and my belief in Oz, per The Wizard of Oz, and any of you who know me through the SEO field, combine the two and you won't be at all surprised the surreal feeling as I find myself back here just outside the Emerald City of NY again after a stay away for a couple of years. And being back I also find myself working for MOZ as a SME, or "subject matter expert". Hmmm. I can work with that.

There's these two other SME peeps. They're Drs Pete and Tom. I'm no doc, PhD or otherwise. Thank goodness I'm spared the date science of all this. Let me get all mechanical. Let's focus on the field of data engineering. What we're doing almost always in my industry, and presumably on a lot of others, is first "feeling out" new processes and methodologies and then repeat refined and improved versions of those processes at different times, from different places, and with different input according to some criteria.

Get to that point and you've mastered a lot of tech. Even if you do it all manually using Excel or GSheets and are importing data from whatever sources and your process is great and you produce a deliverable that brings a lot of actionable value to exactly those who need it, the truth and fact is you could be doing it even better truly automated. Cut Excel and the manual steps out of the process and insert a reliable event scheduler capable of interacting with the Internet and sending emails into the picture, and you've got the hello world of all automated services, including AI.

It's hard to argue getting Linux services running is a highly valuable technical skill in today and tomorrows world.

You have the ability to cast magic spells today. No really, you do. Bear with me for a moment. Technology already has advanced to a point where it is indistinguishable from magic. Do you burn your computers from sand? Can you produce the code that enables the Internet and the device you're reading this on right now?

Some boastful hubris full few may lie yes, but the truth is the fruits of modern common technology are far behind the understanding and production-ability of any one human. Tony Stark's are still imaginary. Even Elon who can make his own satellite networks must stand on the shoulders of other giants. Elon, you, and everyone else on this planet interfaces and interacts with tech through words or hand gestures under very particular contexts. You carry a magic wand in your pocket. This provides one now very common spell-casting context.l: that of a mobile phone using consumer.

To cast magic spells you need access to a special energy-infused implement that contains various recipes for taking advantage of the nature of our world to produce a variety of unlikely yet desirable effects. The implements are computers, phones and the like. The energy is of course electricity. And the spells were once called apps, living on vastly larger miraculous infrastructures called networks. I'll be advocating here the use of yet another variety of spells here known as scripts which also run on networks. Or more specifically, on a node of a network—a.k.a. A server in the Internet.

My goal is to take you from Windows or Mac laptop user to Linux server admin and junior devops person and data engineer in just a few days. Things you'll be able to do from that role of power include starting Python projects in a web browser that crawl, scrape, hit APIs, automate other web browsers, pull back and save the raw data locally and then processes this data in a series of steps doing such things as joining multiple data sources on common fields like URL, this combining crawl and SERP data, for example. Results can be formatted into an Excel sheet with embedded graphs and the results automatically emailed to yourself and/or a list of other email addresses which might include a boss, customer, client or other stakeholder for whom that report is highly valuable and actionable.

Such "deliverables" as we know these things in marketing agency world are usually tedious and manual things to produce. Maybe it starts with keyword research and a site-crawl and ends with a gap-analysis and subject matter content recommendation replete with sample ideas or content to get you started, thanks to large language model (LLM) AI. However you do it, it's a lot of steps and a lot of seemingly I avoided touch-points by humans.

I'm here to tell you almost all those touch-points are actually automatable, most easily if you start out in a Jupyter Notebook that's back-ended with a genuine Linux version of Python. What you do is Mock it up in Linux powered Jupyter just as you would if you were in an Anaconda or JupyterLab-Desktop installed version. The difference being that it's now much easier to directly use your work for 24x7 "headless" automation under the new unified Linux server system, systemd.

The way JupyterLab itself is running on your Windows or Mac laptop actually serves as the template for your first Hello World Linux service. While laptops go to sleep and won't really run 24x7, you will have a reference instance from which to duplicate the exact same environment, minus the Windows or Mac laptop with either some generic cloud Linux instance such as Amazon AWS EC2 also known as Infrastructure as a Service (IaaS) or on a Raspberry Pi or some other cheap local hardware you control and can keep running maybe on your home network, thus avoiding cloud expenses and dependencies.

The upshot of all this is that you are like a wizard now with a gollum or homunculus to do your bidding. You are like Mickey in The Sorcerer's Apprentice but without the brooms going out of control. You can cast spells that will basically never stop working nor be at a loss for somewhere to run.

Industry suddenly changes on you? No problem. Run somewhere else. First you run there. Then you run there, NP 'cause your code's been kept on POPFOSS. Popular FOSS, that is. And not just popular in the fad or even trendy fashion. Java was popular but then Oracle bought Java and started suing people. Your tech isn't save unless the licenses it was released under says so. Apache and MIT licenses are pretty good, as is GPL2 under which Linux is licensed.

So many popular platforms have decided to use Linux as this lowest readily humanly accesses interoperable portable API-layer. That is to say humans work in Linux environments regularly whereas they may not be expected to do so at lower levels like the assembly code for hardware drivers where a deep intimate familiarity with the architecture of particular hardware is required. We shy away from all that with our magic lessons. Those are often powerful but also brittle and short-lived dark arts tied to dying platforms. They are not my interest.

Scripts that reliably knit together deliverables and, we'll, deliver them! That's my interest. It's always about automation. But let's call that Excel or Juputer Notebook level of automation where you have to sit there and hit a button each time you want the deliverable, or worst yet, each part of the deliverable with variable input handled manually, type-1 automation. It's not really automate. You just maybe feel like or because some of your steps may be automated.

Type-2 automation doesn't really kick in until you get a human out of the per-instance picture. 20 or 10,000 deliverable could've be delivered every day and it would take you as a human physically no more effort than delivering one. This is the goal we're working towards so you can thus get more work done in less time with less effort for more compensation and reward for your efforts. We strive to work from a position of abundance, doling out exactly what everyone needs at a competitive and fair enough price that it does not drive them to learn how to do the same work for themselves if they were so inclined.

In this way you will always earn your keep as a talented technical SEO. The type of SEO I describe could just as well be called a Data Engineer and their talents could just as well be adapted into the world of Data Science, finance and many others. It is a path replete with job security unlike the now common and passé abilities to do certain programming like things on Excel or GSheets with macros, VBA or AppScript. The language of your magical incantations, often Python with a sprinkling of the Pandas library and it's like, are less brittle and more timeless than VBA and AppScript. They are certainly less dependent on proprietary for-profit vendor products.

Data has value. Proprietary tools, not so much so. Proprietary tools that give you access to data, but only through their proprietary interfaces is a trick. The trick is to pay for and get the data without hardwiring yourself, your habits and your muscle memory to a particular proprietary tool on a particular proprietary hardware platform. That's a double-whammy of vulnerability to sudden catastrophic obsolescence I try to avoid. If you're lucky, the proprietary interface is that of a Web browser or formal API. In either of those cases, you can still automate against it.

Browser automation is a very deep and special sort of magic I always used to consider too arcane and brittle. Why create new spells that will cease to work in a few years and are flaky to boot even when they are working? This is how it was, or at least felt for me under Selenium, PhantomJS and many similar such things over the years. That is until Google included the Chrome DevTools API that enabled the Chrome Inspector which enabled the Puppeteer Chrome automation library. Microsoft hired its lead developers and added a native Python client library and support for Firefox and WebDev and called it Playwright. Between Google Puppeteer and Microsoft Playwright, browser automation has matured. It's time to code their expression into 24x7 automated scripts.

I know this article is an awful lot to absorb. This is why I make such a modest first step of just activating WSL on your Windows laptop or MultiPass Ubuntu on your Mac. Unfortuanly what goes into making an instance of Linux-hosted JupyterLab then accessible to the Windows or Mac side is not so straight forward. This, plus systemd being turned off by default, I believe are the 2 main barriers to this baby-step approach to hands-on Linux from being more popular. In my estimation we are just one properly pre-configured WSL Linix server away from a Jupyter+Linux revolution that bridges the gap between Jupyter "Lost" mode where you have to sit there and hit a button versus true (Type-2) 24x7 Linux daemon automaton.


## Categories

<ul>
<li><h4><a href='/moz/'>MOZ</a></h4></li>
<li><h4><a href='/python/'>Python</a></h4></li>
<li><h4><a href='/nyc/'>NYC</a></h4></li>
<li><h4><a href='/vim/'>Vim</a></h4></li>
<li><h4><a href='/linux/'>Linux</a></h4></li>
<li><h4><a href='/mac/'>Mac</a></h4></li>
<li><h4><a href='/excel/'>Excel</a></h4></li>
<li><h4><a href='/ai/'>AI</a></h4></li>
<li><h4><a href='/lpvg/'>LPvg</a></h4></li>
<li><h4><a href='/wsl/'>WSL</a></h4></li>
<li><h4><a href='/jupyterlab/'>JupyterLab</a></h4></li>
<li><h4><a href='/git/'>Git</a></h4></li>
<li><h4><a href='/seo/'>SEO</a></h4></li>
<li><h4><a href='/automation/'>Automation</a></h4></li></ul>